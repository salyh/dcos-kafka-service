# Contributing to the Kafka Framework

<!-- TOC START: generated by generate-md-toc.py, do not edit below this line -->

- [Getting started](#getting-started)
  - [Build](#build)
  - [Unit Tests](#unit-tests)
  - [Integration Tests](#integration-tests)
  - [Run in DCOS](#run-in-dcos)
    - [Deploy from local custom Universe](#deploy-from-local-custom-universe)
    - [Deploy from custom branch in Universe repo](#deploy-from-custom-branch-in-universe-repo)
- [Working with the [mesos-commons](https://github.com/mesosphere/mesos-commons) submodule](#working-with-the-mesos-commonshttpsgithubcommesospheremesos-commons-submodule)

<!-- TOC END: generated by generate-md-toc.py, do not edit above this line -->

## Getting started

### Build

``` bash
git clone https://github.com/mesosphere/dcos-kafka-service
cd dcos-kafka-service
./gradlew clean check build
```

#### Build CLI

Prerequisites:
- Go 1.5+ with `GOPATH` defined

``` bash
cd cli/
./build-cli.sh
./dcos-kafka/dcos-kafka-linux kafka -h
```

### Unit Tests

``` bash
./gradlew test
```

## Integration Tests

The Kafka framework uses [shakedown](https://github.com/dcos/shakedown) for specifying integration tests against a DC/OS cluster. The environment setup logic is specified in `integration/run.sh`, which relies for now on the `dcos-tests` repo having been cloned into this one. The `shakedown` test suite is easily run manually if you have a DC/OS cluster already on hand. In this case, you need only install `shakedown` and its dependencies into a virtualenv and then run it with your DC/OS cluster URL as a command-line argument:

    $ cd integration
    $ virtualenv -p python3.5 env
    $ source env/bin/activate
    (env) $ pip install -r requirements.txt
    (env) $ shakedown --dcos-url $(dcos config show core.dcos_url) --ssh-key-file $CLUSTER_KEY_FILE tests/

### Run in DCOS

Prerequisites:
- Have a DCOS cluster somewhere
- Install [dcos-cli](https://docs.mesosphere.com/administration/introcli/cli/)

#### Deploy from a custom Universe

Get the link to the Universe zip (e.g. from the "upload" step of your PR's build). With that in hand:

``` bash
dcos package repo add --index=0 repo-name https://uri.to.build/universe-name.zip
dcos package install kafka
```

If you're testing a config change that you want to be in effect at framework launch:

``` bash
dcos package install kafka options=/path/to/options.json
```
